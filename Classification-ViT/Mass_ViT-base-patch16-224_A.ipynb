{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ViT-based model using Transfer-Learning\n",
    "---\n",
    "#### Model: google/vit-large-patch16-224, descongelando las últimas 3 capas del encoder\n",
    "#### Epochs: 30\n",
    "#### Dataset: images_3categories_balanced\n",
    "#### Cambios:\n",
    "- DropOut:\n",
    "    - Clasificador 0\n",
    "    - HiddenLayer 0\n",
    "    - AttentionLayer 0\n",
    "- Learning Rate 3e-4     "
   ],
   "id": "7022885cdaf44b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:19.030111Z",
     "start_time": "2024-10-20T02:06:19.025971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parámetros\n",
    "_model = 'google/vit-base-patch16-224'\n",
    "# path al checkpoint a cargar, None si no existe\n",
    "_checkpoint = None\n",
    "_output = 'SavedModels/Mass_ViT-large-patch16-224_A'  # path para guardar el modelo\n",
    "\n",
    "_dataset = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/Masses_3categories'\n",
    "\n",
    "# path para guardar el dataset con split\n",
    "_dataset_split_path = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/Masses_3categories_split'  \n",
    "\n",
    "# Si el dataset ya está separado en train, validation y test ->  _dataset_split=_dataset_split_path. \n",
    "# Si no está separado -> _dataset_split=None.\n",
    "_dataset_split = _dataset_split_path  \n",
    "\n",
    "_batch_size = 16\n",
    "_learning_rate = 3e-4\n",
    "_epochs = 30  \n",
    "\n",
    "# DropOut\n",
    "_dp_clasificador = 0.0\n",
    "_dp_hidden_layer = 0.0\n",
    "_dp_attention_layer= 0.0\n",
    "\n",
    "num_layers_to_unfreeze = 5  # Definir el número de capas a descongelar, None eoc"
   ],
   "id": "70a22524132806c4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:21.878721Z",
     "start_time": "2024-10-20T02:06:19.032315Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from Utils import *"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga de datos",
   "id": "86c5c376167db015"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:22.022075Z",
     "start_time": "2024-10-20T02:06:21.977432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    dataset = load_dataset(_dataset)\n",
    "else:\n",
    "    # Cargar el dataset previamente guardado\n",
    "    dataset = load_from_disk(_dataset_split_path)\n",
    "\n",
    "dataset"
   ],
   "id": "3cc4f4afb99d5cf2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 251\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Revisión de categorías",
   "id": "74ee833516aa9480"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:22.037573Z",
     "start_time": "2024-10-20T02:06:22.035083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = dataset['train'].features['label'].names\n",
    "print(len(labels),labels)\n",
    "\n",
    "label2id = {c:idx for idx,c in enumerate(labels)}\n",
    "id2label = {idx:c for idx,c in enumerate(labels)}"
   ],
   "id": "672104ff2885bdeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['benigno', 'maligno', 'sospechoso']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Muestra de ejemplos",
   "id": "8a5e0a4c31f70014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:22.061994Z",
     "start_time": "2024-10-20T02:06:22.059559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_samples(ds,rows,cols):\n",
    "    samples = ds.shuffle().select(np.arange(rows*cols)) # selecting random images\n",
    "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
    "    # plotting\n",
    "    for i in range(rows*cols):\n",
    "        img = samples[i]['image']\n",
    "        label = samples[i]['label']\n",
    "        fig.add_subplot(rows,cols,i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "            \n",
    "# show_samples(dataset['train'],rows=3,cols=5)"
   ],
   "id": "2e09d39396d652ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Dataset",
   "id": "65cd6f013528a8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:22.076794Z",
     "start_time": "2024-10-20T02:06:22.073693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "    eval_dataset = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "    \n",
    "    \n",
    "    # Recombinar los splits \n",
    "    \n",
    "    final_dataset = DatasetDict({\n",
    "        'train': split_dataset['train'],\n",
    "        'validation': eval_dataset['train'],\n",
    "        'test': eval_dataset['test']\n",
    "    })\n",
    "    # Guardar el dataset dividido\n",
    "    final_dataset.save_to_disk(_dataset_split_path)\n",
    "\n",
    "else:\n",
    "    final_dataset = dataset\n",
    "final_dataset"
   ],
   "id": "826ff9fdce47b2e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 251\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:23.398957Z",
     "start_time": "2024-10-20T02:06:22.092842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Número de imágenes por clases en cada split')\n",
    "clases_split = pd.DataFrame(columns=['split', 'benigno', 'maligno', 'sospechoso'])\n",
    "for key in final_dataset:\n",
    "    split = pd.DataFrame(final_dataset[key])\n",
    "    num = split['label'].value_counts().sort_index()\n",
    "    clases_split.loc[len(clases_split)] = [key, *num]\n",
    "    #print(num.sort_index())\n",
    "clases_split"
   ],
   "id": "7c0520fb8246ae8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes por clases en cada split\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        split  benigno  maligno  sospechoso\n",
       "0       train      664      683         654\n",
       "1  validation       80       81          89\n",
       "2        test       90       70          91"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>benigno</th>\n",
       "      <th>maligno</th>\n",
       "      <th>sospechoso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>664</td>\n",
       "      <td>683</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocesamiento de las imágenes",
   "id": "54d16d02617d0642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:24.287286Z",
     "start_time": "2024-10-20T02:06:23.421309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor = AutoImageProcessor.from_pretrained(_model, use_fast=True)\n",
    "processor"
   ],
   "id": "1c2cd9e3e4ab5a4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTImageProcessorFast {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessorFast\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:24.312478Z",
     "start_time": "2024-10-20T02:06:24.310163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transforms(batch):\n",
    "    batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
    "    inputs = processor(batch['image'],return_tensors='pt')\n",
    "    inputs['labels'] = batch['label']  # Las clases ya están en formato numérico\n",
    "    return inputs"
   ],
   "id": "fd8e91d20395f822",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:24.335808Z",
     "start_time": "2024-10-20T02:06:24.321568Z"
    }
   },
   "cell_type": "code",
   "source": "processed_dataset = final_dataset.with_transform(transforms)",
   "id": "7fd84c61b445fd27",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Collation",
   "id": "3c20e0c2fcab0cbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:24.347075Z",
     "start_time": "2024-10-20T02:06:24.345020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ],
   "id": "b594c7a07efc3686",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Métricas de evaluación",
   "id": "248fd8bb2ba4efb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:28.911816Z",
     "start_time": "2024-10-20T02:06:24.353918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Accuracy no requiere el parámetro average\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    \n",
    "    # Las demás métricas sí requieren el parámetro average para multiclase\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels, average='macro')['precision']\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels, average='macro')['recall']\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score,\n",
    "        'f1': f1_score\n",
    "    }"
   ],
   "id": "eeb8010325f0f0cc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga del modelo",
   "id": "952d173ae5c464b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.541072Z",
     "start_time": "2024-10-20T02:06:28.918217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clase personalizada que añade dropout antes de la capa final de clasificación\n",
    "class CustomViTForImageClassification(ViTForImageClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        # Dropout adicional antes de la capa final\n",
    "        self.additional_dropout = nn.Dropout(_dp_clasificador)  # Dropout antes del clasificador\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.vit(pixel_values)  # Obtenemos la salida del modelo ViT\n",
    "        \n",
    "        # Usamos el primer token [CLS] de la salida\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] está en la posición 0\n",
    "        \n",
    "        # Aplicamos dropout adicional antes de la clasificación\n",
    "        pooled_output = self.additional_dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Asegúrate de que las etiquetas sean tipo long (para clasificación)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Configuramos el modelo base con Dropout en las capas internas del ViT\n",
    "model = CustomViTForImageClassification.from_pretrained(\n",
    "    _model,\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    "    hidden_dropout_prob=_dp_hidden_layer,  # Dropout en las capas internas del modelo\n",
    "    attention_probs_dropout_prob=_dp_attention_layer,  # Dropout en las capas de atención\n",
    "    ignore_mismatched_sizes = True\n",
    ")"
   ],
   "id": "90238aad36c0de2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Arquitectura del modelo",
   "id": "922184390f5b66e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.551436Z",
     "start_time": "2024-10-20T02:06:30.548442Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "46712562a7213709",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (additional_dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Congelar todas las capas, menos el clasificador",
   "id": "de3fe87175e49406"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.560681Z",
     "start_time": "2024-10-20T02:06:30.558304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name,p in model.named_parameters():\n",
    "    if not name.startswith('classifier'):\n",
    "        p.requires_grad = False"
   ],
   "id": "7b12d0b8faee7367",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.571658Z",
     "start_time": "2024-10-20T02:06:30.569002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "print(f\"{num_params = :,} | {trainable_params = :,}\")"
   ],
   "id": "64c82a89eda67be7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params = 85,800,963 | trainable_params = 2,307\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Descongelar capas del encoder para fine-tuning",
   "id": "5ed4701c8e3fa107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.580697Z",
     "start_time": "2024-10-20T02:06:30.578872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtener el número total de capas en el encoder\n",
    "num_total_layers = len(list(model.vit.encoder.layer))  # Debería ser 24 para ViT-Large, 12 para ViT-base\n",
    "print(num_total_layers)"
   ],
   "id": "94cb222cd820fbde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.590668Z",
     "start_time": "2024-10-20T02:06:30.588172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Si se descongelan capas\n",
    "if num_layers_to_unfreeze is not None:\n",
    "    # Calcular el índice a partir del cual descongelar\n",
    "    unfreeze_from = num_total_layers - num_layers_to_unfreeze\n",
    "    \n",
    "    # Iterar sobre todas las capas del encoder\n",
    "    for idx, layer in enumerate(model.vit.encoder.layer):\n",
    "        if idx >= unfreeze_from:\n",
    "            # Descongelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            # Congelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n"
   ],
   "id": "7b3a8cb360656483",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.603997Z",
     "start_time": "2024-10-20T02:06:30.601118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mostrar el número total de parámetros y los entrenables después de descongelar\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Después de descongelar las últimas {num_layers_to_unfreeze} capas:\")\n",
    "print(f\"Total de parámetros: {num_params:,}\")\n",
    "print(f\"Parámetros entrenables: {trainable_params:,}\")"
   ],
   "id": "e145df6d86c1cc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de descongelar las últimas 5 capas:\n",
      "Total de parámetros: 85,800,963\n",
      "Parámetros entrenables: 35,441,667\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.616190Z",
     "start_time": "2024-10-20T02:06:30.614165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Revisión de trainable por capa\n",
    "for name, param in model.named_parameters():\n",
    "    status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
    "    #print(f\"{name}: {status}\")"
   ],
   "id": "f7dfb567949b7bbf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "19a3a741baf42170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:30.646917Z",
     "start_time": "2024-10-20T02:06:30.623975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=_output,\n",
    "    per_device_train_batch_size=_batch_size,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=_epochs,  # Epochs a entrenar -> Revisar\n",
    "    learning_rate=_learning_rate,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard',\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ],
   "id": "541994dbbce332e6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:31.187709Z",
     "start_time": "2024-10-20T02:06:30.655553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"validation\"],\n",
    "    tokenizer=processor\n",
    ")"
   ],
   "id": "30f59f8a406a04ef",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T02:06:31.275758Z",
     "start_time": "2024-10-20T02:06:31.273438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS enabled\")"
   ],
   "id": "56a200df21ff907e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-20T02:06:46.878370Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f3df38c3b841d8a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='658' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 658/3780 05:02 < 24:00, 2.17 it/s, Epoch 5.21/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.959500</td>\n",
       "      <td>0.833345</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.568464</td>\n",
       "      <td>0.595926</td>\n",
       "      <td>0.561729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.671727</td>\n",
       "      <td>0.635491</td>\n",
       "      <td>0.572687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.969052</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.627359</td>\n",
       "      <td>0.629372</td>\n",
       "      <td>0.584272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>1.000210</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.651216</td>\n",
       "      <td>0.634221</td>\n",
       "      <td>0.638523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>1.195677</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.613769</td>\n",
       "      <td>0.543468</td>\n",
       "      <td>0.516801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:34:23.467154Z",
     "start_time": "2024-10-19T16:43:46.173900Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "7fb997a65c2644c1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluación del modelo",
   "id": "7a9240869110b2e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:59:07.350868Z",
     "start_time": "2024-10-20T01:58:55.748762Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "bca36b8e1d96cbe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.0670344829559326,\n",
       " 'eval_accuracy': 0.649402390438247,\n",
       " 'eval_precision': 0.6472742563535402,\n",
       " 'eval_recall': 0.6686202686202686,\n",
       " 'eval_f1': 0.6534963244640665}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inferencia en conjunto de test ",
   "id": "b0e855e955ca27b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:59:29.960692Z",
     "start_time": "2024-10-20T01:59:18.367587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = final_dataset['test']\n",
    "processed_samples = samples.with_transform(transforms)\n",
    "predictions = trainer.predict(processed_samples).predictions.argmax(axis=1) # labels predichas"
   ],
   "id": "f37bb4fbf9efd886",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:51:13.415107Z",
     "start_time": "2024-10-12T16:51:13.376970Z"
    }
   },
   "cell_type": "code",
   "source": "show_predictions(rows=5,cols=5, samples_=samples, predictions_=predictions, id2label_=id2label)",
   "id": "12a188f84c9f3779",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mshow_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mcols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mid2label_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mid2label\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/Utils.py:30\u001B[0m, in \u001B[0;36mshow_predictions\u001B[0;34m(rows, cols, samples_, predictions_, id2label_)\u001B[0m\n\u001B[1;32m     28\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(cols \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m, rows \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(indices):\n\u001B[0;32m---> 30\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43msamples_\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# Obtener la imagen correspondiente al índice seleccionado\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m predictions_[idx]  \u001B[38;5;66;03m# Obtener la predicción correspondiente al índice\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Crear la etiqueta para mostrar la etiqueta verdadera y la predicción\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2742\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2740\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2741\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2742\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2727\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2725\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m   2726\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[0;32m-> 2727\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[1;32m   2729\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:636\u001B[0m, in \u001B[0;36mformat_table\u001B[0;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    635\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m table\n\u001B[0;32m--> 636\u001B[0m query_type \u001B[38;5;241m=\u001B[39m \u001B[43mkey_to_query_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:556\u001B[0m, in \u001B[0;36mkey_to_query_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, (\u001B[38;5;28mslice\u001B[39m, \u001B[38;5;28mrange\u001B[39m, Iterable)):\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 556\u001B[0m \u001B[43m_raise_bad_key_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:46\u001B[0m, in \u001B[0;36m_raise_bad_key_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_raise_bad_key_type\u001B[39m(key: Any):\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong key type: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(key)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Expected one of int, slice, range, str or Iterable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     48\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matriz de confusión ❌",
   "id": "97916219ffa54a0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "f6f7fbb54f99d3f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Iterar por más epochs ❌",
   "id": "4cb217670e463742"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer.args.num_train_epochs = 30  # Para entrenar hasta la época 20\n",
    "trainer.train(resume_from_checkpoint=_checkpoint)"
   ],
   "id": "6f532223cd642edd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876336Z",
     "start_time": "2024-10-15T17:59:58.726151Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "81df7794f48301f2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876469Z",
     "start_time": "2024-10-15T18:00:02.130178Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "e34356d41f6d33da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8503161072731018,\n",
       " 'eval_accuracy': 0.611185086551265,\n",
       " 'eval_precision': 0.6176820549739529,\n",
       " 'eval_recall': 0.6137534374966717,\n",
       " 'eval_f1': 0.597174189764872,\n",
       " 'eval_runtime': 34.361,\n",
       " 'eval_samples_per_second': 21.856,\n",
       " 'eval_steps_per_second': 2.736,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:25:29.089937Z",
     "start_time": "2024-10-19T15:25:29.088073Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "1827c30c0aae817e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "139cfc3ed6ac8ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
