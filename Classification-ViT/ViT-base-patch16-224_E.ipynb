{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ViT-based model using Transfer-Learning\n",
    "---\n",
    "#### Model: google/vit-base-patch16-224, descongelando las últimas 3 capas del encoder\n",
    "#### Epochs: 20\n",
    "#### Dataset: images_3categories_balanced\n",
    "#### Cambios:\n",
    "- DropOut:\n",
    "    - Clasificador 0\n",
    "    - HiddenLayer 0\n",
    "    - AttentionLayer 0\n",
    "- Learning Rate 3e-4     "
   ],
   "id": "7022885cdaf44b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:10:56.771637Z",
     "start_time": "2024-10-17T17:10:56.767978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parámetros\n",
    "_model = 'google/vit-base-patch16-224'\n",
    "# path al checkpoint a cargar, None si no existe\n",
    "_checkpoint = 'SavedModels/ViT-base-patch16-224_D/checkpoint-3760'\n",
    "_output = 'SavedModels/vit-base-patch16-224_D'  # path para guardar el modelo\n",
    "\n",
    "_dataset = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/images_3categories_balanced'\n",
    "\n",
    "# path para guardar el dataset con split\n",
    "_dataset_split_path = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/images_3categories_balanced_split'  \n",
    "\n",
    "# Si el dataset ya está separado en train, validation y test ->  _dataset_split=_dataset_split_path. \n",
    "# Si no está separado -> _dataset_split=None.\n",
    "_dataset_split = _dataset_split_path  \n",
    "\n",
    "_batch_size = 16\n",
    "_learning_rate = 3e-4\n",
    "_epochs = 20\n",
    "\n",
    "# DropOut\n",
    "_dp_clasificador = 0.0\n",
    "_dp_hidden_layer = 0.0\n",
    "_dp_attention_layer= 0.0\n",
    "\n",
    "num_layers_to_unfreeze = 3  # Definir el número de capas a descongelar, None eoc"
   ],
   "id": "70a22524132806c4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:41.653169Z",
     "start_time": "2024-10-17T17:08:39.202458Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from Utils import *"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga de datos",
   "id": "86c5c376167db015"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:41.829916Z",
     "start_time": "2024-10-17T17:08:41.737501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    dataset = load_dataset(_dataset)\n",
    "else:\n",
    "    # Cargar el dataset previamente guardado\n",
    "    dataset = load_from_disk(_dataset_split_path)\n",
    "\n",
    "dataset"
   ],
   "id": "3cc4f4afb99d5cf2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 6003\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Revisión de categorías",
   "id": "74ee833516aa9480"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:41.846678Z",
     "start_time": "2024-10-17T17:08:41.844102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = dataset['train'].features['label'].names\n",
    "print(len(labels),labels)\n",
    "\n",
    "label2id = {c:idx for idx,c in enumerate(labels)}\n",
    "id2label = {idx:c for idx,c in enumerate(labels)}"
   ],
   "id": "672104ff2885bdeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['calcificaciones', 'masas', 'no_encontrado']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Muestra de ejemplos",
   "id": "8a5e0a4c31f70014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:41.861580Z",
     "start_time": "2024-10-17T17:08:41.859024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_samples(ds,rows,cols):\n",
    "    samples = ds.shuffle().select(np.arange(rows*cols)) # selecting random images\n",
    "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
    "    # plotting\n",
    "    for i in range(rows*cols):\n",
    "        img = samples[i]['image']\n",
    "        label = samples[i]['label']\n",
    "        fig.add_subplot(rows,cols,i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "            \n",
    "# show_samples(dataset['train'],rows=3,cols=5)"
   ],
   "id": "2e09d39396d652ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Dataset",
   "id": "65cd6f013528a8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:41.885756Z",
     "start_time": "2024-10-17T17:08:41.882341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "    eval_dataset = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "    \n",
    "    \n",
    "    # Recombinar los splits \n",
    "    \n",
    "    final_dataset = DatasetDict({\n",
    "        'train': split_dataset['train'],\n",
    "        'validation': eval_dataset['train'],\n",
    "        'test': eval_dataset['test']\n",
    "    })\n",
    "    # Guardar el dataset dividido\n",
    "    final_dataset.save_to_disk(_dataset_split_path)\n",
    "\n",
    "else:\n",
    "    final_dataset = dataset\n",
    "final_dataset"
   ],
   "id": "826ff9fdce47b2e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 6003\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocesamiento de las imágenes",
   "id": "54d16d02617d0642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:43.011257Z",
     "start_time": "2024-10-17T17:08:41.901976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor = AutoImageProcessor.from_pretrained(_model, use_fast=True)\n",
    "processor"
   ],
   "id": "1c2cd9e3e4ab5a4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTImageProcessorFast {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessorFast\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:43.032657Z",
     "start_time": "2024-10-17T17:08:43.030221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transforms(batch):\n",
    "    batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
    "    inputs = processor(batch['image'],return_tensors='pt')\n",
    "    inputs['labels'] = batch['label']  # Las clases ya están en formato numérico\n",
    "    return inputs"
   ],
   "id": "fd8e91d20395f822",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:43.073368Z",
     "start_time": "2024-10-17T17:08:43.039016Z"
    }
   },
   "cell_type": "code",
   "source": "processed_dataset = final_dataset.with_transform(transforms)",
   "id": "7fd84c61b445fd27",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Collation",
   "id": "3c20e0c2fcab0cbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:43.079941Z",
     "start_time": "2024-10-17T17:08:43.077968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ],
   "id": "b594c7a07efc3686",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Métricas de evaluación",
   "id": "248fd8bb2ba4efb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:47.248741Z",
     "start_time": "2024-10-17T17:08:43.084191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Accuracy no requiere el parámetro average\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    \n",
    "    # Las demás métricas sí requieren el parámetro average para multiclase\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels, average='macro')['precision']\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels, average='macro')['recall']\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score,\n",
    "        'f1': f1_score\n",
    "    }"
   ],
   "id": "eeb8010325f0f0cc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga del modelo",
   "id": "952d173ae5c464b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.677255Z",
     "start_time": "2024-10-17T17:08:47.254483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clase personalizada que añade dropout antes de la capa final de clasificación\n",
    "class CustomViTForImageClassification(ViTForImageClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        # Dropout adicional antes de la capa final\n",
    "        self.additional_dropout = nn.Dropout(_dp_clasificador)  # Dropout antes del clasificador\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.vit(pixel_values)  # Obtenemos la salida del modelo ViT\n",
    "        \n",
    "        # Usamos el primer token [CLS] de la salida\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] está en la posición 0\n",
    "        \n",
    "        # Aplicamos dropout adicional antes de la clasificación\n",
    "        pooled_output = self.additional_dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Asegúrate de que las etiquetas sean tipo long (para clasificación)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Configuramos el modelo base con Dropout en las capas internas del ViT\n",
    "model = CustomViTForImageClassification.from_pretrained(\n",
    "    _model,\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    "    hidden_dropout_prob=_dp_hidden_layer,  # Dropout en las capas internas del modelo\n",
    "    attention_probs_dropout_prob=_dp_attention_layer,  # Dropout en las capas de atención\n",
    "    ignore_mismatched_sizes = True\n",
    ")"
   ],
   "id": "90238aad36c0de2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Arquitectura del modelo",
   "id": "922184390f5b66e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.686472Z",
     "start_time": "2024-10-17T17:08:48.683719Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "46712562a7213709",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (additional_dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Congelar todas las capas, menos el clasificador",
   "id": "de3fe87175e49406"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.694659Z",
     "start_time": "2024-10-17T17:08:48.692351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name,p in model.named_parameters():\n",
    "    if not name.startswith('classifier'):\n",
    "        p.requires_grad = False"
   ],
   "id": "7b12d0b8faee7367",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.703752Z",
     "start_time": "2024-10-17T17:08:48.701315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "print(f\"{num_params = :,} | {trainable_params = :,}\")"
   ],
   "id": "64c82a89eda67be7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params = 85,800,963 | trainable_params = 2,307\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Descongelar capas del encoder para fine-tuning",
   "id": "5ed4701c8e3fa107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.711369Z",
     "start_time": "2024-10-17T17:08:48.709537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtener el número total de capas en el encoder\n",
    "num_total_layers = len(list(model.vit.encoder.layer))  # Debería ser 24 para ViT-Large, 12 para ViT-base\n",
    "print(num_total_layers)"
   ],
   "id": "94cb222cd820fbde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.720044Z",
     "start_time": "2024-10-17T17:08:48.717583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Si se descongelan capas\n",
    "if num_layers_to_unfreeze is not None:\n",
    "    # Calcular el índice a partir del cual descongelar\n",
    "    unfreeze_from = num_total_layers - num_layers_to_unfreeze\n",
    "    \n",
    "    # Iterar sobre todas las capas del encoder\n",
    "    for idx, layer in enumerate(model.vit.encoder.layer):\n",
    "        if idx >= unfreeze_from:\n",
    "            # Descongelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            # Congelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n"
   ],
   "id": "7b3a8cb360656483",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.731474Z",
     "start_time": "2024-10-17T17:08:48.728682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mostrar el número total de parámetros y los entrenables después de descongelar\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Después de descongelar las últimas {num_layers_to_unfreeze} capas:\")\n",
    "print(f\"Total de parámetros: {num_params:,}\")\n",
    "print(f\"Parámetros entrenables: {trainable_params:,}\")"
   ],
   "id": "e145df6d86c1cc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de descongelar las últimas 3 capas:\n",
      "Total de parámetros: 85,800,963\n",
      "Parámetros entrenables: 21,265,923\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:48.741590Z",
     "start_time": "2024-10-17T17:08:48.739629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Revisión de trainable por capa\n",
    "for name, param in model.named_parameters():\n",
    "    status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
    "    #print(f\"{name}: {status}\")"
   ],
   "id": "f7dfb567949b7bbf",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "19a3a741baf42170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:11:02.675292Z",
     "start_time": "2024-10-17T17:11:02.671448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=_output,\n",
    "    per_device_train_batch_size=_batch_size,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=_epochs,  # Epochs a entrenar -> Revisar\n",
    "    learning_rate=_learning_rate,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard',\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ],
   "id": "541994dbbce332e6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:11:04.277264Z",
     "start_time": "2024-10-17T17:11:04.266655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"validation\"],\n",
    "    tokenizer=processor\n",
    ")"
   ],
   "id": "30f59f8a406a04ef",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:08:49.289987Z",
     "start_time": "2024-10-17T17:08:49.287846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS enabled\")"
   ],
   "id": "56a200df21ff907e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:58:48.922261Z",
     "start_time": "2024-10-17T17:11:07.095171Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f3df38c3b841d8a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7520' max='7520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7520/7520 47:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.789448</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.640911</td>\n",
       "      <td>0.635132</td>\n",
       "      <td>0.634222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.844624</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.647144</td>\n",
       "      <td>0.589612</td>\n",
       "      <td>0.587487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.493600</td>\n",
       "      <td>0.824898</td>\n",
       "      <td>0.645333</td>\n",
       "      <td>0.652908</td>\n",
       "      <td>0.645119</td>\n",
       "      <td>0.631608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>0.982971</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.672290</td>\n",
       "      <td>0.682128</td>\n",
       "      <td>0.666393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>1.099191</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.643665</td>\n",
       "      <td>0.634412</td>\n",
       "      <td>0.636059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>1.128210</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.664092</td>\n",
       "      <td>0.670398</td>\n",
       "      <td>0.665360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>1.412397</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.661449</td>\n",
       "      <td>0.671028</td>\n",
       "      <td>0.656006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>1.507261</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.672943</td>\n",
       "      <td>0.671572</td>\n",
       "      <td>0.644040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>1.812228</td>\n",
       "      <td>0.661333</td>\n",
       "      <td>0.651691</td>\n",
       "      <td>0.662752</td>\n",
       "      <td>0.644194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.471540</td>\n",
       "      <td>0.649333</td>\n",
       "      <td>0.644466</td>\n",
       "      <td>0.650502</td>\n",
       "      <td>0.646598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>1.678021</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>0.664599</td>\n",
       "      <td>0.671892</td>\n",
       "      <td>0.666986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>1.993160</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.675563</td>\n",
       "      <td>0.685404</td>\n",
       "      <td>0.660942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>1.656654</td>\n",
       "      <td>0.658667</td>\n",
       "      <td>0.652061</td>\n",
       "      <td>0.661041</td>\n",
       "      <td>0.650320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>1.880763</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.658799</td>\n",
       "      <td>0.665818</td>\n",
       "      <td>0.660083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.971395</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.667484</td>\n",
       "      <td>0.676079</td>\n",
       "      <td>0.669436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>2.144998</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.665942</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.663261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>2.116690</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.664020</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.665798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>2.189381</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.660421</td>\n",
       "      <td>0.669597</td>\n",
       "      <td>0.661905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>2.196385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.659383</td>\n",
       "      <td>0.668291</td>\n",
       "      <td>0.660898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>2.205515</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.656529</td>\n",
       "      <td>0.665624</td>\n",
       "      <td>0.658155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7520, training_loss=0.18020155005791086, metrics={'train_runtime': 2861.6715, 'train_samples_per_second': 41.955, 'train_steps_per_second': 2.628, 'total_flos': 9.303771659143127e+18, 'train_loss': 0.18020155005791086, 'epoch': 20.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:58:58.255819Z",
     "start_time": "2024-10-17T17:58:58.035139Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "7fb997a65c2644c1",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluación del modelo",
   "id": "7a9240869110b2e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:59:45.954246Z",
     "start_time": "2024-10-17T17:59:33.668399Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "bca36b8e1d96cbe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 00:12]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7753562331199646,\n",
       " 'eval_accuracy': 0.6391478029294274,\n",
       " 'eval_precision': 0.6483235784678486,\n",
       " 'eval_recall': 0.6341596958174905,\n",
       " 'eval_f1': 0.6354581374718274,\n",
       " 'eval_runtime': 12.2813,\n",
       " 'eval_samples_per_second': 61.15,\n",
       " 'eval_steps_per_second': 7.654,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inferencia en conjunto de test ❌",
   "id": "b0e855e955ca27b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T18:01:38.245881Z",
     "start_time": "2024-10-15T18:01:03.598567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = final_dataset['test']\n",
    "processed_samples = samples.with_transform(transforms)\n",
    "predictions = trainer.predict(processed_samples).predictions.argmax(axis=1) # labels predichas"
   ],
   "id": "f37bb4fbf9efd886",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:51:13.415107Z",
     "start_time": "2024-10-12T16:51:13.376970Z"
    }
   },
   "cell_type": "code",
   "source": "show_predictions(rows=5,cols=5, samples_=samples, predictions_=predictions, id2label_=id2label)",
   "id": "12a188f84c9f3779",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mshow_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mcols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mid2label_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mid2label\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/Utils.py:30\u001B[0m, in \u001B[0;36mshow_predictions\u001B[0;34m(rows, cols, samples_, predictions_, id2label_)\u001B[0m\n\u001B[1;32m     28\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(cols \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m, rows \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(indices):\n\u001B[0;32m---> 30\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43msamples_\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# Obtener la imagen correspondiente al índice seleccionado\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m predictions_[idx]  \u001B[38;5;66;03m# Obtener la predicción correspondiente al índice\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Crear la etiqueta para mostrar la etiqueta verdadera y la predicción\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2742\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2740\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2741\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2742\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2727\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2725\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m   2726\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[0;32m-> 2727\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[1;32m   2729\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:636\u001B[0m, in \u001B[0;36mformat_table\u001B[0;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    635\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m table\n\u001B[0;32m--> 636\u001B[0m query_type \u001B[38;5;241m=\u001B[39m \u001B[43mkey_to_query_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:556\u001B[0m, in \u001B[0;36mkey_to_query_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, (\u001B[38;5;28mslice\u001B[39m, \u001B[38;5;28mrange\u001B[39m, Iterable)):\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 556\u001B[0m \u001B[43m_raise_bad_key_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:46\u001B[0m, in \u001B[0;36m_raise_bad_key_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_raise_bad_key_type\u001B[39m(key: Any):\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong key type: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(key)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Expected one of int, slice, range, str or Iterable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     48\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matriz de confusión ❌",
   "id": "97916219ffa54a0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T18:47:49.797876Z",
     "start_time": "2024-10-21T18:47:49.794897Z"
    }
   },
   "cell_type": "code",
   "source": "#confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "f6f7fbb54f99d3f6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Iterar por más epochs ❌",
   "id": "4cb217670e463742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.875779Z",
     "start_time": "2024-10-15T15:44:19.168186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.args.num_train_epochs = 30  # Para entrenar hasta la época 20\n",
    "trainer.train(resume_from_checkpoint=_checkpoint)"
   ],
   "id": "6f532223cd642edd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julio/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/Users/julio/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7520' max='7520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7520/7520 1:37:22, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.877042</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.589141</td>\n",
       "      <td>0.578162</td>\n",
       "      <td>0.557365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.892163</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.598009</td>\n",
       "      <td>0.582933</td>\n",
       "      <td>0.555253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>0.846069</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.607307</td>\n",
       "      <td>0.608004</td>\n",
       "      <td>0.603711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.591639</td>\n",
       "      <td>0.596593</td>\n",
       "      <td>0.574775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.914073</td>\n",
       "      <td>0.598667</td>\n",
       "      <td>0.611466</td>\n",
       "      <td>0.597818</td>\n",
       "      <td>0.573249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.622742</td>\n",
       "      <td>0.611058</td>\n",
       "      <td>0.595824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.944764</td>\n",
       "      <td>0.614667</td>\n",
       "      <td>0.619614</td>\n",
       "      <td>0.616435</td>\n",
       "      <td>0.583422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.834460</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.610590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.949483</td>\n",
       "      <td>0.605333</td>\n",
       "      <td>0.617413</td>\n",
       "      <td>0.604435</td>\n",
       "      <td>0.581577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.622667</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.622679</td>\n",
       "      <td>0.601622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.905018</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.638718</td>\n",
       "      <td>0.636478</td>\n",
       "      <td>0.621479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.929459</td>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.634131</td>\n",
       "      <td>0.630661</td>\n",
       "      <td>0.614708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.938069</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.632027</td>\n",
       "      <td>0.627886</td>\n",
       "      <td>0.611742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.638563</td>\n",
       "      <td>0.635168</td>\n",
       "      <td>0.618327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.632181</td>\n",
       "      <td>0.616442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7520, training_loss=0.514044954928946, metrics={'train_runtime': 5843.3897, 'train_samples_per_second': 20.546, 'train_steps_per_second': 1.287, 'total_flos': 3.288864877974981e+19, 'train_loss': 0.514044954928946, 'epoch': 20.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876336Z",
     "start_time": "2024-10-15T17:59:58.726151Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "81df7794f48301f2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876469Z",
     "start_time": "2024-10-15T18:00:02.130178Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "e34356d41f6d33da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8503161072731018,\n",
       " 'eval_accuracy': 0.611185086551265,\n",
       " 'eval_precision': 0.6176820549739529,\n",
       " 'eval_recall': 0.6137534374966717,\n",
       " 'eval_f1': 0.597174189764872,\n",
       " 'eval_runtime': 34.361,\n",
       " 'eval_samples_per_second': 21.856,\n",
       " 'eval_steps_per_second': 2.736,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T18:48:09.494821Z",
     "start_time": "2024-10-21T18:48:09.492606Z"
    }
   },
   "cell_type": "code",
   "source": "#confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "1827c30c0aae817e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "139cfc3ed6ac8ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
