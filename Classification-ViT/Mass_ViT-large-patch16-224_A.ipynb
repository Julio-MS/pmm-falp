{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ViT-based model using Transfer-Learning\n",
    "---\n",
    "#### Model: google/vit-large-patch16-224, descongelando las últimas 3 capas del encoder\n",
    "#### Epochs: 30\n",
    "#### Dataset: images_3categories_balanced\n",
    "#### Cambios:\n",
    "- DropOut:\n",
    "    - Clasificador 0\n",
    "    - HiddenLayer 0\n",
    "    - AttentionLayer 0\n",
    "- Learning Rate 3e-4     "
   ],
   "id": "7022885cdaf44b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:07.772534Z",
     "start_time": "2024-10-20T01:35:07.768281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parámetros\n",
    "_model = 'google/vit-large-patch16-224'\n",
    "# path al checkpoint a cargar, None si no existe\n",
    "_checkpoint = None\n",
    "_output = 'SavedModels/Mass_ViT-large-patch16-224_A'  # path para guardar el modelo\n",
    "\n",
    "_dataset = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/Masses_3categories'\n",
    "\n",
    "# path para guardar el dataset con split\n",
    "_dataset_split_path = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/Masses_3categories_split'  \n",
    "\n",
    "# Si el dataset ya está separado en train, validation y test ->  _dataset_split=_dataset_split_path. \n",
    "# Si no está separado -> _dataset_split=None.\n",
    "_dataset_split = None  \n",
    "\n",
    "_batch_size = 16\n",
    "_learning_rate = 3e-4\n",
    "_epochs = 30  # Entrenamiento solo por 10 epochs\n",
    "\n",
    "# DropOut\n",
    "_dp_clasificador = 0.0\n",
    "_dp_hidden_layer = 0.0\n",
    "_dp_attention_layer= 0.0\n",
    "\n",
    "num_layers_to_unfreeze = 5  # Definir el número de capas a descongelar, None eoc"
   ],
   "id": "70a22524132806c4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:10.471790Z",
     "start_time": "2024-10-20T01:35:07.774931Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from Utils import *"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga de datos",
   "id": "86c5c376167db015"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:11.551726Z",
     "start_time": "2024-10-20T01:35:10.576047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    dataset = load_dataset(_dataset)\n",
    "else:\n",
    "    # Cargar el dataset previamente guardado\n",
    "    dataset = load_from_disk(_dataset_split_path)\n",
    "\n",
    "dataset"
   ],
   "id": "3cc4f4afb99d5cf2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/2502 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46ed12ae88e94b099bd0e773e82474cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2502\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Revisión de categorías",
   "id": "74ee833516aa9480"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:11.575199Z",
     "start_time": "2024-10-20T01:35:11.572876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = dataset['train'].features['label'].names\n",
    "print(len(labels),labels)\n",
    "\n",
    "label2id = {c:idx for idx,c in enumerate(labels)}\n",
    "id2label = {idx:c for idx,c in enumerate(labels)}"
   ],
   "id": "672104ff2885bdeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['benigno', 'maligno', 'sospechoso']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Muestra de ejemplos",
   "id": "8a5e0a4c31f70014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:11.599666Z",
     "start_time": "2024-10-20T01:35:11.597252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_samples(ds,rows,cols):\n",
    "    samples = ds.shuffle().select(np.arange(rows*cols)) # selecting random images\n",
    "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
    "    # plotting\n",
    "    for i in range(rows*cols):\n",
    "        img = samples[i]['image']\n",
    "        label = samples[i]['label']\n",
    "        fig.add_subplot(rows,cols,i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "            \n",
    "# show_samples(dataset['train'],rows=3,cols=5)"
   ],
   "id": "2e09d39396d652ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Dataset",
   "id": "65cd6f013528a8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:12.192095Z",
     "start_time": "2024-10-20T01:35:11.621366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if _dataset_split is None:\n",
    "    split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "    eval_dataset = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "    \n",
    "    \n",
    "    # Recombinar los splits \n",
    "    \n",
    "    final_dataset = DatasetDict({\n",
    "        'train': split_dataset['train'],\n",
    "        'validation': eval_dataset['train'],\n",
    "        'test': eval_dataset['test']\n",
    "    })\n",
    "    # Guardar el dataset dividido\n",
    "    final_dataset.save_to_disk(_dataset_split_path)\n",
    "\n",
    "else:\n",
    "    final_dataset = dataset\n",
    "final_dataset"
   ],
   "id": "826ff9fdce47b2e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2001 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e02c3b9f94e941fd890d940065b25235"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bf4ddc8e0094f3aba1790bfc7ffc7d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/251 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7814e60aab9c4e3a9aa04487746f62e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 251\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:13.599516Z",
     "start_time": "2024-10-20T01:35:12.216285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Número de imágenes por clases en cada split')\n",
    "clases_split = pd.DataFrame(columns=['split', 'benigno', 'maligno', 'sospechoso'])\n",
    "for key in final_dataset:\n",
    "    split = pd.DataFrame(final_dataset[key])\n",
    "    num = split['label'].value_counts().sort_index()\n",
    "    clases_split.loc[len(clases_split)] = [key, *num]\n",
    "    #print(num.sort_index())\n",
    "clases_split"
   ],
   "id": "7c0520fb8246ae8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes por clases en cada split\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        split  benigno  maligno  sospechoso\n",
       "0       train      664      683         654\n",
       "1  validation       80       81          89\n",
       "2        test       90       70          91"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>benigno</th>\n",
       "      <th>maligno</th>\n",
       "      <th>sospechoso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>664</td>\n",
       "      <td>683</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocesamiento de las imágenes",
   "id": "54d16d02617d0642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:15.127756Z",
     "start_time": "2024-10-20T01:35:13.621599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor = AutoImageProcessor.from_pretrained(_model, use_fast=True)\n",
    "processor"
   ],
   "id": "1c2cd9e3e4ab5a4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTImageProcessorFast {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessorFast\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:15.159283Z",
     "start_time": "2024-10-20T01:35:15.156981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transforms(batch):\n",
    "    batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
    "    inputs = processor(batch['image'],return_tensors='pt')\n",
    "    inputs['labels'] = batch['label']  # Las clases ya están en formato numérico\n",
    "    return inputs"
   ],
   "id": "fd8e91d20395f822",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:15.197856Z",
     "start_time": "2024-10-20T01:35:15.183249Z"
    }
   },
   "cell_type": "code",
   "source": "processed_dataset = final_dataset.with_transform(transforms)",
   "id": "7fd84c61b445fd27",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Collation",
   "id": "3c20e0c2fcab0cbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:15.212826Z",
     "start_time": "2024-10-20T01:35:15.211087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ],
   "id": "b594c7a07efc3686",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Métricas de evaluación",
   "id": "248fd8bb2ba4efb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:19.261971Z",
     "start_time": "2024-10-20T01:35:15.218680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Accuracy no requiere el parámetro average\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    \n",
    "    # Las demás métricas sí requieren el parámetro average para multiclase\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels, average='macro')['precision']\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels, average='macro')['recall']\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score,\n",
    "        'f1': f1_score\n",
    "    }"
   ],
   "id": "eeb8010325f0f0cc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga del modelo",
   "id": "952d173ae5c464b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.719690Z",
     "start_time": "2024-10-20T01:35:19.269458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clase personalizada que añade dropout antes de la capa final de clasificación\n",
    "class CustomViTForImageClassification(ViTForImageClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        # Dropout adicional antes de la capa final\n",
    "        self.additional_dropout = nn.Dropout(_dp_clasificador)  # Dropout antes del clasificador\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.vit(pixel_values)  # Obtenemos la salida del modelo ViT\n",
    "        \n",
    "        # Usamos el primer token [CLS] de la salida\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] está en la posición 0\n",
    "        \n",
    "        # Aplicamos dropout adicional antes de la clasificación\n",
    "        pooled_output = self.additional_dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Asegúrate de que las etiquetas sean tipo long (para clasificación)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Configuramos el modelo base con Dropout en las capas internas del ViT\n",
    "model = CustomViTForImageClassification.from_pretrained(\n",
    "    _model,\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    "    hidden_dropout_prob=_dp_hidden_layer,  # Dropout en las capas internas del modelo\n",
    "    attention_probs_dropout_prob=_dp_attention_layer,  # Dropout en las capas de atención\n",
    "    ignore_mismatched_sizes = True\n",
    ")"
   ],
   "id": "90238aad36c0de2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomViTForImageClassification were not initialized from the model checkpoint at google/vit-large-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 1024]) in the checkpoint and torch.Size([3, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Arquitectura del modelo",
   "id": "922184390f5b66e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.731260Z",
     "start_time": "2024-10-20T01:35:22.728032Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "46712562a7213709",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (additional_dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Congelar todas las capas, menos el clasificador",
   "id": "de3fe87175e49406"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.751799Z",
     "start_time": "2024-10-20T01:35:22.749280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name,p in model.named_parameters():\n",
    "    if not name.startswith('classifier'):\n",
    "        p.requires_grad = False"
   ],
   "id": "7b12d0b8faee7367",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.767540Z",
     "start_time": "2024-10-20T01:35:22.763981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "print(f\"{num_params = :,} | {trainable_params = :,}\")"
   ],
   "id": "64c82a89eda67be7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params = 303,304,707 | trainable_params = 3,075\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Descongelar capas del encoder para fine-tuning",
   "id": "5ed4701c8e3fa107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.793888Z",
     "start_time": "2024-10-20T01:35:22.791396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtener el número total de capas en el encoder\n",
    "num_total_layers = len(list(model.vit.encoder.layer))  # Debería ser 24 para ViT-Large, 12 para ViT-base\n",
    "print(num_total_layers)"
   ],
   "id": "94cb222cd820fbde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.820125Z",
     "start_time": "2024-10-20T01:35:22.817150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Si se descongelan capas\n",
    "if num_layers_to_unfreeze is not None:\n",
    "    # Calcular el índice a partir del cual descongelar\n",
    "    unfreeze_from = num_total_layers - num_layers_to_unfreeze\n",
    "    \n",
    "    # Iterar sobre todas las capas del encoder\n",
    "    for idx, layer in enumerate(model.vit.encoder.layer):\n",
    "        if idx >= unfreeze_from:\n",
    "            # Descongelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            # Congelar esta capa\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n"
   ],
   "id": "7b3a8cb360656483",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.830156Z",
     "start_time": "2024-10-20T01:35:22.826753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mostrar el número total de parámetros y los entrenables después de descongelar\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Después de descongelar las últimas {num_layers_to_unfreeze} capas:\")\n",
    "print(f\"Total de parámetros: {num_params:,}\")\n",
    "print(f\"Parámetros entrenables: {trainable_params:,}\")"
   ],
   "id": "e145df6d86c1cc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de descongelar las últimas 5 capas:\n",
      "Total de parámetros: 303,304,707\n",
      "Parámetros entrenables: 62,984,195\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.844148Z",
     "start_time": "2024-10-20T01:35:22.841703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Revisión de trainable por capa\n",
    "for name, param in model.named_parameters():\n",
    "    status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
    "    #print(f\"{name}: {status}\")"
   ],
   "id": "f7dfb567949b7bbf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "19a3a741baf42170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:22.868793Z",
     "start_time": "2024-10-20T01:35:22.853668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=_output,\n",
    "    per_device_train_batch_size=_batch_size,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=_epochs,  # Epochs a entrenar -> Revisar\n",
    "    learning_rate=_learning_rate,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard',\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ],
   "id": "541994dbbce332e6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:24.893750Z",
     "start_time": "2024-10-20T01:35:22.876612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"validation\"],\n",
    "    tokenizer=processor\n",
    ")"
   ],
   "id": "30f59f8a406a04ef",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:35:24.978184Z",
     "start_time": "2024-10-20T01:35:24.976026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(\"MPS enabled\")"
   ],
   "id": "56a200df21ff907e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:58:45.426128Z",
     "start_time": "2024-10-20T01:35:53.699311Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "f3df38c3b841d8a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1269' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1269/3780 22:50 < 45:15, 0.92 it/s, Epoch 10.06/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.091200</td>\n",
       "      <td>0.824604</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.591664</td>\n",
       "      <td>0.608215</td>\n",
       "      <td>0.595762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.762900</td>\n",
       "      <td>0.801708</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.604247</td>\n",
       "      <td>0.622564</td>\n",
       "      <td>0.598902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.652300</td>\n",
       "      <td>0.928145</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.611658</td>\n",
       "      <td>0.617869</td>\n",
       "      <td>0.570202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>1.075831</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.677795</td>\n",
       "      <td>0.685655</td>\n",
       "      <td>0.664541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>1.625736</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.688302</td>\n",
       "      <td>0.637241</td>\n",
       "      <td>0.645231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>1.647024</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.686360</td>\n",
       "      <td>0.658136</td>\n",
       "      <td>0.659653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>1.709930</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.646370</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.641163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>2.004382</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.646203</td>\n",
       "      <td>0.658707</td>\n",
       "      <td>0.629898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>1.598497</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.652117</td>\n",
       "      <td>0.636764</td>\n",
       "      <td>0.641306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>2.067034</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.647274</td>\n",
       "      <td>0.668620</td>\n",
       "      <td>0.653496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:11]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2052\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2050\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   2051\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2052\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2053\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2054\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2055\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2056\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2057\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2345\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2342\u001B[0m     rng_to_sync \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2344\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 2345\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   2346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_batched_samples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m   2348\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minclude_num_input_tokens_seen\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/accelerate/data_loader.py:561\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    559\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m send_to_device(current_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_non_blocking)\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_state_dict()\n\u001B[0;32m--> 561\u001B[0m next_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_batches:\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m current_batch\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    672\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 673\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    675\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[0;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2746\u001B[0m, in \u001B[0;36mDataset.__getitems__\u001B[0;34m(self, keys)\u001B[0m\n\u001B[1;32m   2744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitems__\u001B[39m(\u001B[38;5;28mself\u001B[39m, keys: List) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[1;32m   2745\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2746\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2747\u001B[0m     n_examples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch[\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(batch))])\n\u001B[1;32m   2748\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [{col: array[i] \u001B[38;5;28;01mfor\u001B[39;00m col, array \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_examples)]\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2742\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2740\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2741\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2742\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2727\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2725\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m   2726\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[0;32m-> 2727\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[1;32m   2729\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:639\u001B[0m, in \u001B[0;36mformat_table\u001B[0;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[1;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:407\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[0;34m(self, pa_table, query_type)\u001B[0m\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_column(pa_table)\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 407\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:521\u001B[0m, in \u001B[0;36mCustomFormatter.format_batch\u001B[0;34m(self, pa_table)\u001B[0m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m    520\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_batch(pa_table)\n\u001B[0;32m--> 521\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_features_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    522\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(batch)\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:228\u001B[0m, in \u001B[0;36mPythonFeaturesDecoder.decode_batch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[0;32m--> 228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;28;01melse\u001B[39;00m batch\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/features/features.py:2084\u001B[0m, in \u001B[0;36mFeatures.decode_batch\u001B[0;34m(self, batch, token_per_repo_id)\u001B[0m\n\u001B[1;32m   2081\u001B[0m decoded_batch \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2082\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column_name, column \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   2083\u001B[0m     decoded_batch[column_name] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 2084\u001B[0m         \u001B[43m[\u001B[49m\n\u001B[1;32m   2085\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2086\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   2087\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   2088\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcolumn\u001B[49m\n\u001B[1;32m   2089\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   2090\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_column_requires_decoding[column_name]\n\u001B[1;32m   2091\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m column\n\u001B[1;32m   2092\u001B[0m     )\n\u001B[1;32m   2093\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m decoded_batch\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/features/features.py:2085\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   2081\u001B[0m decoded_batch \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2082\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column_name, column \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   2083\u001B[0m     decoded_batch[column_name] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2084\u001B[0m         [\n\u001B[0;32m-> 2085\u001B[0m             \u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2086\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2087\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2088\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m column\n\u001B[1;32m   2089\u001B[0m         ]\n\u001B[1;32m   2090\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_column_requires_decoding[column_name]\n\u001B[1;32m   2091\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m column\n\u001B[1;32m   2092\u001B[0m     )\n\u001B[1;32m   2093\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m decoded_batch\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/features/features.py:1403\u001B[0m, in \u001B[0;36mdecode_nested_example\u001B[0;34m(schema, obj, token_per_repo_id)\u001B[0m\n\u001B[1;32m   1400\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(schema, (Audio, Image)):\n\u001B[1;32m   1401\u001B[0m     \u001B[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001B[39;00m\n\u001B[1;32m   1402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m schema\u001B[38;5;241m.\u001B[39mdecode:\n\u001B[0;32m-> 1403\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mschema\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1404\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/features/image.py:188\u001B[0m, in \u001B[0;36mImage.decode_example\u001B[0;34m(self, value, token_per_repo_id)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     image \u001B[38;5;241m=\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mopen(BytesIO(bytes_))\n\u001B[0;32m--> 188\u001B[0m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# to avoid \"Too many open files\" errors\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m image\u001B[38;5;241m.\u001B[39mgetexif()\u001B[38;5;241m.\u001B[39mget(PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mExifTags\u001B[38;5;241m.\u001B[39mBase\u001B[38;5;241m.\u001B[39mOrientation) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    190\u001B[0m     image \u001B[38;5;241m=\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImageOps\u001B[38;5;241m.\u001B[39mexif_transpose(image)\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/PIL/ImageFile.py:293\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[1;32m    292\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 293\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:34:23.467154Z",
     "start_time": "2024-10-19T16:43:46.173900Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "7fb997a65c2644c1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluación del modelo",
   "id": "7a9240869110b2e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:59:07.350868Z",
     "start_time": "2024-10-20T01:58:55.748762Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "bca36b8e1d96cbe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.0670344829559326,\n",
       " 'eval_accuracy': 0.649402390438247,\n",
       " 'eval_precision': 0.6472742563535402,\n",
       " 'eval_recall': 0.6686202686202686,\n",
       " 'eval_f1': 0.6534963244640665}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inferencia en conjunto de test ",
   "id": "b0e855e955ca27b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:59:29.960692Z",
     "start_time": "2024-10-20T01:59:18.367587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = final_dataset['test']\n",
    "processed_samples = samples.with_transform(transforms)\n",
    "predictions = trainer.predict(processed_samples).predictions.argmax(axis=1) # labels predichas"
   ],
   "id": "f37bb4fbf9efd886",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:51:13.415107Z",
     "start_time": "2024-10-12T16:51:13.376970Z"
    }
   },
   "cell_type": "code",
   "source": "show_predictions(rows=5,cols=5, samples_=samples, predictions_=predictions, id2label_=id2label)",
   "id": "12a188f84c9f3779",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mshow_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mcols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mid2label_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mid2label\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/Utils.py:30\u001B[0m, in \u001B[0;36mshow_predictions\u001B[0;34m(rows, cols, samples_, predictions_, id2label_)\u001B[0m\n\u001B[1;32m     28\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(cols \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m, rows \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(indices):\n\u001B[0;32m---> 30\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43msamples_\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# Obtener la imagen correspondiente al índice seleccionado\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m predictions_[idx]  \u001B[38;5;66;03m# Obtener la predicción correspondiente al índice\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Crear la etiqueta para mostrar la etiqueta verdadera y la predicción\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2742\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2740\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2741\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2742\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2727\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2725\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[1;32m   2726\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[0;32m-> 2727\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[1;32m   2729\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:636\u001B[0m, in \u001B[0;36mformat_table\u001B[0;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    635\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m table\n\u001B[0;32m--> 636\u001B[0m query_type \u001B[38;5;241m=\u001B[39m \u001B[43mkey_to_query_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:556\u001B[0m, in \u001B[0;36mkey_to_query_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, (\u001B[38;5;28mslice\u001B[39m, \u001B[38;5;28mrange\u001B[39m, Iterable)):\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 556\u001B[0m \u001B[43m_raise_bad_key_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:46\u001B[0m, in \u001B[0;36m_raise_bad_key_type\u001B[0;34m(key)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_raise_bad_key_type\u001B[39m(key: Any):\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong key type: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(key)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Expected one of int, slice, range, str or Iterable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     48\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Wrong key type: '173' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matriz de confusión",
   "id": "97916219ffa54a0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T01:59:32.403886Z",
     "start_time": "2024-10-20T01:59:29.964330Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "f6f7fbb54f99d3f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Iterar por más epochs ❌",
   "id": "4cb217670e463742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.875779Z",
     "start_time": "2024-10-15T15:44:19.168186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.args.num_train_epochs = 30  # Para entrenar hasta la época 20\n",
    "trainer.train(resume_from_checkpoint=_checkpoint)"
   ],
   "id": "6f532223cd642edd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julio/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/Users/julio/Documents/PMM/Codigos/Test1/Classification-ViT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7520' max='7520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7520/7520 1:37:22, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.877042</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.589141</td>\n",
       "      <td>0.578162</td>\n",
       "      <td>0.557365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.892163</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.598009</td>\n",
       "      <td>0.582933</td>\n",
       "      <td>0.555253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>0.846069</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.607307</td>\n",
       "      <td>0.608004</td>\n",
       "      <td>0.603711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.591639</td>\n",
       "      <td>0.596593</td>\n",
       "      <td>0.574775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.914073</td>\n",
       "      <td>0.598667</td>\n",
       "      <td>0.611466</td>\n",
       "      <td>0.597818</td>\n",
       "      <td>0.573249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.622742</td>\n",
       "      <td>0.611058</td>\n",
       "      <td>0.595824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.944764</td>\n",
       "      <td>0.614667</td>\n",
       "      <td>0.619614</td>\n",
       "      <td>0.616435</td>\n",
       "      <td>0.583422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.834460</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.610590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.949483</td>\n",
       "      <td>0.605333</td>\n",
       "      <td>0.617413</td>\n",
       "      <td>0.604435</td>\n",
       "      <td>0.581577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.622667</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.622679</td>\n",
       "      <td>0.601622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.905018</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.638718</td>\n",
       "      <td>0.636478</td>\n",
       "      <td>0.621479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.929459</td>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.634131</td>\n",
       "      <td>0.630661</td>\n",
       "      <td>0.614708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.938069</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.632027</td>\n",
       "      <td>0.627886</td>\n",
       "      <td>0.611742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.638563</td>\n",
       "      <td>0.635168</td>\n",
       "      <td>0.618327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.592900</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.635671</td>\n",
       "      <td>0.632181</td>\n",
       "      <td>0.616442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7520, training_loss=0.514044954928946, metrics={'train_runtime': 5843.3897, 'train_samples_per_second': 20.546, 'train_steps_per_second': 1.287, 'total_flos': 3.288864877974981e+19, 'train_loss': 0.514044954928946, 'epoch': 20.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876336Z",
     "start_time": "2024-10-15T17:59:58.726151Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model()",
   "id": "81df7794f48301f2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T17:03:40.876469Z",
     "start_time": "2024-10-15T18:00:02.130178Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(processed_dataset['test'])",
   "id": "e34356d41f6d33da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8503161072731018,\n",
       " 'eval_accuracy': 0.611185086551265,\n",
       " 'eval_precision': 0.6176820549739529,\n",
       " 'eval_recall': 0.6137534374966717,\n",
       " 'eval_f1': 0.597174189764872,\n",
       " 'eval_runtime': 34.361,\n",
       " 'eval_samples_per_second': 21.856,\n",
       " 'eval_steps_per_second': 2.736,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:25:29.089937Z",
     "start_time": "2024-10-19T15:25:29.088073Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(samples_=samples, predictions_=predictions)",
   "id": "1827c30c0aae817e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "139cfc3ed6ac8ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
