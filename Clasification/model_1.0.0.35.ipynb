{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a745ca9f060c5c4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:14:19.694391Z",
     "start_time": "2024-09-11T02:14:15.385648Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, ReLU, Flatten, Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arquitectura de la Red"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e2fba5df611bc4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julio/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-10 23:14:19.704084: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-09-10 23:14:19.704111: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-09-10 23:14:19.704115: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-09-10 23:14:19.704130: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 23:14:19.704140: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m320\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m128\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu (\u001B[38;5;33mReLU\u001B[0m)                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │         \u001B[38;5;34m9,248\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m128\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_1 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │         \u001B[38;5;34m9,248\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m128\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_2 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m18,496\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_3 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m36,928\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_4 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m75\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m73,856\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │           \u001B[38;5;34m512\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_5 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │       \u001B[38;5;34m147,584\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │           \u001B[38;5;34m512\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_6 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m38\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_7 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m295,168\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │         \u001B[38;5;34m1,024\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_7 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m19\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_8 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m512\u001B[0m)    │     \u001B[38;5;34m1,180,160\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m512\u001B[0m)    │         \u001B[38;5;34m2,048\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_8 (\u001B[38;5;33mReLU\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m512\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12800\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │    \u001B[38;5;34m26,216,448\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │     \u001B[38;5;34m4,196,352\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │         \u001B[38;5;34m4,098\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">26,216,448</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m32,192,898\u001B[0m (122.81 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,192,898</span> (122.81 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m32,190,402\u001B[0m (122.80 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,190,402</span> (122.80 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m2,496\u001B[0m (9.75 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "###################  Convolutional layer 1  ###################\n",
    "# Primera capa convolucional (conv1)\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), padding='same', input_shape=(299, 299, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Segunda capa convolucional (conv1.1)\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Tercera capa convolucional (conv1.2)\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Primera capa de MaxPooling (pool1)\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))  # Aplicar dropout\n",
    "\n",
    "###################  Convolutional layer 2  ###################\n",
    "# Segunda capa convolucional (conv2.1) \n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Segunda capa convolucional (conv2.2) \n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Segunda capa de MaxPooling \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))  # Aplicar dropout\n",
    "\n",
    "###################  Convolutional layer 3  ###################\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Tercera capa de MaxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))  # Aplicar dropout\n",
    "\n",
    "###################  Convolutional layer 4  ###################\n",
    "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Cuarta capa de MaxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))  # Aplicar dropout\n",
    "\n",
    "###################  Convolutional layer 5  ###################\n",
    "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "\n",
    "# Quinta capa de MaxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.1))  # Aplicar dropout\n",
    "\n",
    "###################  Flatten layer  ###################\n",
    "model.add(Flatten())\n",
    "\n",
    "################### Fully Connected Layers ###################\n",
    "model.add(Dense(2048, activation='relu'))  # Capa densa con 2048 neuronas\n",
    "model.add(Dropout(0.5))  # Aplicar dropout\n",
    "\n",
    "model.add(Dense(2048, activation='relu'))  # Otra capa densa con 2048 neuronas\n",
    "model.add(Dropout(0.5))  # Aplicar dropout\n",
    "\n",
    "################### Output Layer ###################\n",
    "model.add(Dense(2, activation='softmax'))  # Asumiendo que tienes 2 clases (binario)\n",
    "\n",
    "\n",
    "# Resumen del modelo hasta ahora\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:14:20.419315Z",
     "start_time": "2024-09-11T02:14:19.701160Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de datos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc7358ebb3f5308f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 815 files belonging to 2 classes.\n",
      "Found 192 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "train_path = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/ss1/training'\n",
    "test_path = '/Users/julio/Documentos-Local/data/VinDr-Mammo/subsets/ss1/test'\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=train_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "tests_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=test_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(299, 299),\n",
    "    color_mode='grayscale'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:14:20.518799Z",
     "start_time": "2024-09-11T02:14:20.420628Z"
    }
   },
   "id": "ac87a859a4847a92",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aumentación y Escalamiento"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e45aea7c7f78944e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "# Agregar capas de augmentación dentro del modelo\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "# Normalizar los datos dentro del modelo\n",
    "normalization_layer = Rescaling(1./255)\n",
    "\n",
    "# Aplicar augmentación y normalización en el flujo del modelo\n",
    "augmented_train_dataset = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "normalized_train_dataset = augmented_train_dataset.map(\n",
    "    lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "normalized_test_dataset = tests_ds.map(\n",
    "    lambda x, y: (normalization_layer(x), y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:14:40.977493Z",
     "start_time": "2024-09-11T02:14:40.885051Z"
    }
   },
   "id": "e4f5f71a1b6a76bd",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de los pesos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04d87f14260f304"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 21:00:57.799261: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /Users/julio/Documentos-Local/data/model_s1.0.0.35b.96.bu30.ckpt-100000: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "Unable to open table file /Users/julio/Documentos-Local/data/model_s1.0.0.35b.96.bu30.ckpt-100000: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:92\u001B[0m, in \u001B[0;36mNewCheckpointReader\u001B[0;34m(filepattern)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mCheckpointReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepattern\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# issue with throwing python exceptions from C++.\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Unable to open table file /Users/julio/Documentos-Local/data/model_s1.0.0.35b.96.bu30.ckpt-100000: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mDataLossError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mCheckpoint(model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Restaurar los pesos\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m status \u001B[38;5;241m=\u001B[39m \u001B[43mcheckpoint\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrestore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Verificar que el estado de restauración es exitoso\u001B[39;00m\n\u001B[1;32m     11\u001B[0m status\u001B[38;5;241m.\u001B[39massert_existing_objects_matched()\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:2732\u001B[0m, in \u001B[0;36mCheckpoint.restore\u001B[0;34m(self, save_path, options)\u001B[0m\n\u001B[1;32m   2729\u001B[0m   save_path \u001B[38;5;241m=\u001B[39m path_helpers\u001B[38;5;241m.\u001B[39mget_variables_path(save_path)\n\u001B[1;32m   2731\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2732\u001B[0m   status \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2733\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m   2734\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()  \u001B[38;5;66;03m# Ensure restore operations have completed.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:2595\u001B[0m, in \u001B[0;36mCheckpoint.read\u001B[0;34m(self, save_path, options)\u001B[0m\n\u001B[1;32m   2593\u001B[0m   save_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(save_path)\n\u001B[1;32m   2594\u001B[0m options \u001B[38;5;241m=\u001B[39m options \u001B[38;5;129;01mor\u001B[39;00m checkpoint_options\u001B[38;5;241m.\u001B[39mCheckpointOptions()\n\u001B[0;32m-> 2595\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_saver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrestore\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2596\u001B[0m metrics\u001B[38;5;241m.\u001B[39mAddCheckpointReadDuration(\n\u001B[1;32m   2597\u001B[0m     api_label\u001B[38;5;241m=\u001B[39m_CHECKPOINT_V2,\n\u001B[1;32m   2598\u001B[0m     microseconds\u001B[38;5;241m=\u001B[39m_get_duration_microseconds(start_time, time\u001B[38;5;241m.\u001B[39mtime()))\n\u001B[1;32m   2599\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/checkpoint/checkpoint.py:1456\u001B[0m, in \u001B[0;36mTrackableSaver.restore\u001B[0;34m(self, save_path, options)\u001B[0m\n\u001B[1;32m   1454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _ASYNC_CHECKPOINT_THREAD \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1455\u001B[0m   _ASYNC_CHECKPOINT_THREAD\u001B[38;5;241m.\u001B[39mjoin()\n\u001B[0;32m-> 1456\u001B[0m reader \u001B[38;5;241m=\u001B[39m \u001B[43mpy_checkpoint_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNewCheckpointReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1457\u001B[0m graph_building \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n\u001B[1;32m   1458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m graph_building:\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:96\u001B[0m, in \u001B[0;36mNewCheckpointReader\u001B[0;34m(filepattern)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# issue with throwing python exceptions from C++.\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m---> 96\u001B[0m   \u001B[43merror_translator\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PMM/Codigos/Test1/Clasification/.venv/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:40\u001B[0m, in \u001B[0;36merror_translator\u001B[0;34m(e)\u001B[0m\n\u001B[1;32m     38\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mInvalidArgumentError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, error_message)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnable to open table file\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m error_message:\n\u001B[0;32m---> 40\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mDataLossError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, error_message)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to find the saved tensor slices\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m error_message \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot convertible to numpy dtype\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m error_message):\n\u001B[1;32m     43\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mInternalError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, error_message)\n",
      "\u001B[0;31mDataLossError\u001B[0m: Unable to open table file /Users/julio/Documentos-Local/data/model_s1.0.0.35b.96.bu30.ckpt-100000: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?"
     ]
    }
   ],
   "source": [
    "# Ruta del checkpoint \n",
    "checkpoint_path = '/Users/julio/Documentos-Local/data/model_s1.0.0.35b.96.bu30.ckpt-100000'\n",
    "\n",
    "# Crear el objeto checkpoint\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "# Restaurar los pesos\n",
    "status = checkpoint.restore(checkpoint_path)\n",
    "\n",
    "# Verificar que el estado de restauración es exitoso\n",
    "status.assert_existing_objects_matched()\n",
    "print(\"Pesos restaurados desde el checkpoint.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:00:57.863551Z",
     "start_time": "2024-09-11T00:00:57.816688Z"
    }
   },
   "id": "148d6650976f08be",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Congelar todas las capas convolucionales (hasta Flatten)\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
    "        layer.trainable = False\n",
    "\n",
    "print(\"Capas convolucionales congeladas.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caba01e10e599992"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"Capa: {layer.name} - ¿Entrenable?: {layer.trainable}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "981aae75f6cea564"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447af2824660c23d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compilar el modelo con un optimizador y función de pérdida adecuados\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'recall'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:14:46.989232Z",
     "start_time": "2024-09-11T02:14:46.970222Z"
    }
   },
   "id": "f7637ea3c6223e46",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 281ms/step - accuracy: 0.7568 - loss: 0.5165 - recall: 0.7568 - val_accuracy: 0.7396 - val_loss: 0.5478 - val_recall: 0.7396\n",
      "Epoch 2/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7681 - loss: 0.4863 - recall: 0.7681 - val_accuracy: 0.7396 - val_loss: 0.5606 - val_recall: 0.7396\n",
      "Epoch 3/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7653 - loss: 0.5076 - recall: 0.7653 - val_accuracy: 0.7396 - val_loss: 0.5703 - val_recall: 0.7396\n",
      "Epoch 4/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 275ms/step - accuracy: 0.7727 - loss: 0.4772 - recall: 0.7727 - val_accuracy: 0.7396 - val_loss: 0.5762 - val_recall: 0.7396\n",
      "Epoch 5/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7623 - loss: 0.5195 - recall: 0.7623 - val_accuracy: 0.7396 - val_loss: 0.6078 - val_recall: 0.7396\n",
      "Epoch 6/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7496 - loss: 0.5128 - recall: 0.7496 - val_accuracy: 0.7396 - val_loss: 0.4750 - val_recall: 0.7396\n",
      "Epoch 7/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7715 - loss: 0.4515 - recall: 0.7715 - val_accuracy: 0.7396 - val_loss: 0.5511 - val_recall: 0.7396\n",
      "Epoch 8/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7775 - loss: 0.4663 - recall: 0.7775 - val_accuracy: 0.7396 - val_loss: 0.4940 - val_recall: 0.7396\n",
      "Epoch 9/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7655 - loss: 0.4675 - recall: 0.7655 - val_accuracy: 0.7396 - val_loss: 0.5539 - val_recall: 0.7396\n",
      "Epoch 10/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7634 - loss: 0.4590 - recall: 0.7634 - val_accuracy: 0.7396 - val_loss: 0.5281 - val_recall: 0.7396\n",
      "Epoch 11/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7585 - loss: 0.5223 - recall: 0.7585 - val_accuracy: 0.7396 - val_loss: 0.5025 - val_recall: 0.7396\n",
      "Epoch 12/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7741 - loss: 0.4854 - recall: 0.7741 - val_accuracy: 0.7396 - val_loss: 0.5999 - val_recall: 0.7396\n",
      "Epoch 13/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7660 - loss: 0.4652 - recall: 0.7660 - val_accuracy: 0.7396 - val_loss: 0.6032 - val_recall: 0.7396\n",
      "Epoch 14/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 268ms/step - accuracy: 0.7720 - loss: 0.4671 - recall: 0.7720 - val_accuracy: 0.7396 - val_loss: 0.6031 - val_recall: 0.7396\n",
      "Epoch 15/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7669 - loss: 0.4614 - recall: 0.7669 - val_accuracy: 0.7396 - val_loss: 0.5367 - val_recall: 0.7396\n",
      "Epoch 16/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7533 - loss: 0.4566 - recall: 0.7533 - val_accuracy: 0.7396 - val_loss: 0.6194 - val_recall: 0.7396\n",
      "Epoch 17/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7605 - loss: 0.4735 - recall: 0.7605 - val_accuracy: 0.7396 - val_loss: 0.5880 - val_recall: 0.7396\n",
      "Epoch 18/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7712 - loss: 0.4661 - recall: 0.7712 - val_accuracy: 0.7396 - val_loss: 0.6178 - val_recall: 0.7396\n",
      "Epoch 19/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 268ms/step - accuracy: 0.7638 - loss: 0.4776 - recall: 0.7638 - val_accuracy: 0.7396 - val_loss: 0.6189 - val_recall: 0.7396\n",
      "Epoch 20/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 279ms/step - accuracy: 0.7412 - loss: 0.5165 - recall: 0.7412 - val_accuracy: 0.7396 - val_loss: 0.4537 - val_recall: 0.7396\n",
      "Epoch 21/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 277ms/step - accuracy: 0.7640 - loss: 0.4745 - recall: 0.7640 - val_accuracy: 0.7396 - val_loss: 0.4574 - val_recall: 0.7396\n",
      "Epoch 22/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 273ms/step - accuracy: 0.7602 - loss: 0.4857 - recall: 0.7602 - val_accuracy: 0.7396 - val_loss: 0.5152 - val_recall: 0.7396\n",
      "Epoch 23/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7590 - loss: 0.4732 - recall: 0.7590 - val_accuracy: 0.7396 - val_loss: 0.6010 - val_recall: 0.7396\n",
      "Epoch 24/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 276ms/step - accuracy: 0.7747 - loss: 0.4682 - recall: 0.7747 - val_accuracy: 0.7396 - val_loss: 0.4780 - val_recall: 0.7396\n",
      "Epoch 25/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 273ms/step - accuracy: 0.7627 - loss: 0.4533 - recall: 0.7627 - val_accuracy: 0.7396 - val_loss: 0.5801 - val_recall: 0.7396\n",
      "Epoch 26/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 273ms/step - accuracy: 0.7694 - loss: 0.4453 - recall: 0.7694 - val_accuracy: 0.7396 - val_loss: 0.6198 - val_recall: 0.7396\n",
      "Epoch 27/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 273ms/step - accuracy: 0.7548 - loss: 0.4865 - recall: 0.7548 - val_accuracy: 0.7396 - val_loss: 0.4313 - val_recall: 0.7396\n",
      "Epoch 28/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7793 - loss: 0.4353 - recall: 0.7793 - val_accuracy: 0.7396 - val_loss: 0.6179 - val_recall: 0.7396\n",
      "Epoch 29/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7731 - loss: 0.4530 - recall: 0.7731 - val_accuracy: 0.7396 - val_loss: 0.5399 - val_recall: 0.7396\n",
      "Epoch 30/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 278ms/step - accuracy: 0.7482 - loss: 0.4601 - recall: 0.7482 - val_accuracy: 0.7396 - val_loss: 0.4942 - val_recall: 0.7396\n",
      "Epoch 31/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7665 - loss: 0.4584 - recall: 0.7665 - val_accuracy: 0.7396 - val_loss: 0.5211 - val_recall: 0.7396\n",
      "Epoch 32/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 275ms/step - accuracy: 0.7702 - loss: 0.4514 - recall: 0.7702 - val_accuracy: 0.7396 - val_loss: 0.5990 - val_recall: 0.7396\n",
      "Epoch 33/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7590 - loss: 0.4496 - recall: 0.7590 - val_accuracy: 0.7396 - val_loss: 0.6259 - val_recall: 0.7396\n",
      "Epoch 34/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7881 - loss: 0.4161 - recall: 0.7881 - val_accuracy: 0.7396 - val_loss: 0.4750 - val_recall: 0.7396\n",
      "Epoch 35/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7646 - loss: 0.4456 - recall: 0.7646 - val_accuracy: 0.7396 - val_loss: 0.4607 - val_recall: 0.7396\n",
      "Epoch 36/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7640 - loss: 0.5024 - recall: 0.7640 - val_accuracy: 0.7396 - val_loss: 0.6237 - val_recall: 0.7396\n",
      "Epoch 37/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7787 - loss: 0.4355 - recall: 0.7787 - val_accuracy: 0.7396 - val_loss: 0.4602 - val_recall: 0.7396\n",
      "Epoch 38/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7743 - loss: 0.4346 - recall: 0.7743 - val_accuracy: 0.7396 - val_loss: 0.5409 - val_recall: 0.7396\n",
      "Epoch 39/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7789 - loss: 0.4447 - recall: 0.7789 - val_accuracy: 0.7396 - val_loss: 0.4288 - val_recall: 0.7396\n",
      "Epoch 40/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7644 - loss: 0.4640 - recall: 0.7644 - val_accuracy: 0.7396 - val_loss: 0.5100 - val_recall: 0.7396\n",
      "Epoch 41/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 273ms/step - accuracy: 0.7578 - loss: 0.4365 - recall: 0.7578 - val_accuracy: 0.7396 - val_loss: 0.4513 - val_recall: 0.7396\n",
      "Epoch 42/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7675 - loss: 0.4370 - recall: 0.7675 - val_accuracy: 0.7396 - val_loss: 0.5617 - val_recall: 0.7396\n",
      "Epoch 43/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 269ms/step - accuracy: 0.7605 - loss: 0.4440 - recall: 0.7605 - val_accuracy: 0.7396 - val_loss: 0.4765 - val_recall: 0.7396\n",
      "Epoch 44/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7653 - loss: 0.4374 - recall: 0.7653 - val_accuracy: 0.7396 - val_loss: 0.6209 - val_recall: 0.7396\n",
      "Epoch 45/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 268ms/step - accuracy: 0.7618 - loss: 0.4264 - recall: 0.7618 - val_accuracy: 0.7396 - val_loss: 0.5910 - val_recall: 0.7396\n",
      "Epoch 46/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 281ms/step - accuracy: 0.7765 - loss: 0.3923 - recall: 0.7765 - val_accuracy: 0.7396 - val_loss: 0.5988 - val_recall: 0.7396\n",
      "Epoch 47/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 270ms/step - accuracy: 0.7643 - loss: 0.4254 - recall: 0.7643 - val_accuracy: 0.7396 - val_loss: 0.6325 - val_recall: 0.7396\n",
      "Epoch 48/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7448 - loss: 0.3964 - recall: 0.7448 - val_accuracy: 0.7396 - val_loss: 0.5089 - val_recall: 0.7396\n",
      "Epoch 49/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7632 - loss: 0.4082 - recall: 0.7632 - val_accuracy: 0.7396 - val_loss: 0.6699 - val_recall: 0.7396\n",
      "Epoch 50/50\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7433 - loss: 0.4496 - recall: 0.7433 - val_accuracy: 0.7396 - val_loss: 0.5535 - val_recall: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo congelando las capas convolucionales\n",
    "history = model.fit(\n",
    "    normalized_train_dataset,\n",
    "    validation_data=normalized_test_dataset,\n",
    "    epochs=50\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T00:16:00.401315Z",
     "start_time": "2024-09-11T00:10:00.335807Z"
    }
   },
   "id": "e955a7a7df980bf7",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 23:14:48.937296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 341ms/step - accuracy: 0.6699 - loss: 8.7201 - recall: 0.6699 - val_accuracy: 0.7396 - val_loss: 0.6007 - val_recall: 0.7396\n",
      "Epoch 2/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7485 - loss: 1.1411 - recall: 0.7485 - val_accuracy: 0.7396 - val_loss: 0.6067 - val_recall: 0.7396\n",
      "Epoch 3/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7305 - loss: 1.0090 - recall: 0.7305 - val_accuracy: 0.7396 - val_loss: 0.6080 - val_recall: 0.7396\n",
      "Epoch 4/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7290 - loss: 1.2360 - recall: 0.7290 - val_accuracy: 0.7396 - val_loss: 0.6252 - val_recall: 0.7396\n",
      "Epoch 5/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 279ms/step - accuracy: 0.7195 - loss: 1.0653 - recall: 0.7195 - val_accuracy: 0.7396 - val_loss: 0.6012 - val_recall: 0.7396\n",
      "Epoch 6/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7673 - loss: 0.5847 - recall: 0.7673 - val_accuracy: 0.7396 - val_loss: 0.6368 - val_recall: 0.7396\n",
      "Epoch 7/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7597 - loss: 0.5786 - recall: 0.7597 - val_accuracy: 0.7396 - val_loss: 0.6232 - val_recall: 0.7396\n",
      "Epoch 8/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 275ms/step - accuracy: 0.7579 - loss: 0.5328 - recall: 0.7579 - val_accuracy: 0.7396 - val_loss: 0.6079 - val_recall: 0.7396\n",
      "Epoch 9/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7498 - loss: 0.5329 - recall: 0.7498 - val_accuracy: 0.7396 - val_loss: 0.6419 - val_recall: 0.7396\n",
      "Epoch 10/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 276ms/step - accuracy: 0.7534 - loss: 0.5334 - recall: 0.7534 - val_accuracy: 0.7396 - val_loss: 0.6026 - val_recall: 0.7396\n",
      "Epoch 11/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 277ms/step - accuracy: 0.7394 - loss: 0.5467 - recall: 0.7394 - val_accuracy: 0.7396 - val_loss: 0.5787 - val_recall: 0.7396\n",
      "Epoch 12/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 275ms/step - accuracy: 0.7556 - loss: 0.5749 - recall: 0.7556 - val_accuracy: 0.7396 - val_loss: 0.6140 - val_recall: 0.7396\n",
      "Epoch 13/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 272ms/step - accuracy: 0.7593 - loss: 0.5127 - recall: 0.7593 - val_accuracy: 0.7396 - val_loss: 0.6330 - val_recall: 0.7396\n",
      "Epoch 14/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 278ms/step - accuracy: 0.7643 - loss: 0.5238 - recall: 0.7643 - val_accuracy: 0.7396 - val_loss: 0.6019 - val_recall: 0.7396\n",
      "Epoch 15/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7594 - loss: 0.5321 - recall: 0.7594 - val_accuracy: 0.7396 - val_loss: 0.5857 - val_recall: 0.7396\n",
      "Epoch 16/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 271ms/step - accuracy: 0.7533 - loss: 0.5229 - recall: 0.7533 - val_accuracy: 0.7396 - val_loss: 0.6015 - val_recall: 0.7396\n",
      "Epoch 17/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 277ms/step - accuracy: 0.7500 - loss: 0.4966 - recall: 0.7500 - val_accuracy: 0.7396 - val_loss: 0.5712 - val_recall: 0.7396\n",
      "Epoch 18/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7832 - loss: 0.4703 - recall: 0.7832 - val_accuracy: 0.7396 - val_loss: 0.5914 - val_recall: 0.7396\n",
      "Epoch 19/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7717 - loss: 0.4942 - recall: 0.7717 - val_accuracy: 0.7396 - val_loss: 0.5794 - val_recall: 0.7396\n",
      "Epoch 20/20\n",
      "\u001B[1m26/26\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 274ms/step - accuracy: 0.7572 - loss: 0.4989 - recall: 0.7572 - val_accuracy: 0.7396 - val_loss: 0.5177 - val_recall: 0.7396\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    normalized_train_dataset,\n",
    "    validation_data=normalized_test_dataset,\n",
    "    epochs=20\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T02:17:21.511974Z",
     "start_time": "2024-09-11T02:14:48.895173Z"
    }
   },
   "id": "598fec19795ac42d",
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
